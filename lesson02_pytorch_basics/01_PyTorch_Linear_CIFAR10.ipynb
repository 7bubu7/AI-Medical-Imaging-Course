{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12bm2it_hrE0lawM4lW1Q4XX0TlbrcY78","timestamp":1626618134049}],"private_outputs":true,"gpuType":"T4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"7JqIcnWvwMpc"},"source":["# Basic module\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm # progress bar\n","\n","# PyTorch\n","import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import transforms # 資料前處理"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4LsiyFhmR_2N"},"source":["# print version of PyTorch\n","torch.__version__, torchvision.__version__"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["執行階段 -> 變更執行階段類型"],"metadata":{"id":"tSQwW30z1jKC"}},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"5J7psdFU10xL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WXajqeGESoSn"},"source":["#### Prepare CIFAR10 Dataset\n","\n","*   torch vision datasets: https://pytorch.org/vision/stable/datasets.html\n","*   CIFAR10 label\n","\n","0: airplane\n","1: automobile\n","2: bird\n","3: cat\n","4: deer\n","5: dog\n","6: frog\n","7: horse\n","8: ship\n","9: truck"]},{"cell_type":"code","metadata":{"id":"gDg9Aq-aSCNF"},"source":["# Define Parameters\n","NUM_CLASS = 10\n","# Class name and class mapping\n","class_names = [\n","    'airplane',\n","    'automobile',\n","    'bird',\n","    'cat',\n","    'deer',\n","    'dog',\n","    'frog',\n","    'horse',\n","    'ship',\n","    'truck'\n","]\n","class_map = {cls: i for i, cls in enumerate(class_names)}\n","print(class_map)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### torch.utils.data.Dataset\n","\n","https://pytorch.org/docs/stable/data.html?highlight=dataset#torch.utils.data.Dataset\n","\n","*   read **1** sample (img, label)\n","*   Convert to **Torch.Tensor**\n","* Datasets provided by torchvision https://pytorch.org/vision/stable/datasets.html\n"],"metadata":{"id":"moN1UGPNwBXR"}},{"cell_type":"code","metadata":{"id":"c0QABVe3VT49"},"source":["# Download dataset\n","train_ds = torchvision.datasets.CIFAR10('data', # saved path\n","    train=True, # training or testing set\n","    download=True # download dataset from internet\n",")\n","val_ds = torchvision.datasets.CIFAR10('data',\n","    train=False,\n","    download=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X1SDBy2lWFd3"},"source":["# Check your dataset\n","print('Number of training   samples:', len(train_ds))\n","print('Number of validation samples:', len(val_ds))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aSl_QHt8WWIa"},"source":["# Random select a sample\n","idx = np.random.randint(low=0, high=len(train_ds))\n","img, label = train_ds[idx]\n","\n","# Type of img and label\n","print(idx)\n","print(type(img), type(label))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1zAuBoFQXEZn"},"source":["# Convert to np.ndarray and show image\n","img_np = np.array(img)\n","print('img shape: ', img_np.shape)\n","print('label: ', label)\n","print('class name: ', class_names[label])\n","plt.imshow(img_np)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0zMyLJrtZyyE"},"source":["#### Data Proprocess\n","\n","\n","\n","1.   Convert **PIL.Image** to **torch.FloatTensor** (張量)\n","  \n","\n","*   Converts a **PIL Image or numpy.ndarray** (H, W, C) in the range [0, 255] to a **torch.FloatTensor** of shape (C, H, W) in the range [0.0, 1.0]\n","\n","2.   TODO: Data Augmentation, ... etc\n","\n"]},{"cell_type":"code","metadata":{"id":"5qMzb9CKZoY7"},"source":["preprocess = transforms.Compose([\n","    transforms.ToTensor(), # Convert to Tensor\n","    # ...\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"38oH2kqAb02w"},"source":["# Build dataset with data preprocess\n","train_ds = torchvision.datasets.CIFAR10('data',\n","    train=True,\n","    download=True,\n","    transform=preprocess)\n","val_ds = torchvision.datasets.CIFAR10('data',\n","    train=False,\n","    download=True,\n","    transform=preprocess)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I9WPxmL-dBDW"},"source":["#### Combine Dataset with DataLoader\n","\n","**torch.utils.data.DataLoader**: https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n","\n","* form a **batch**\n","* data sampler\n","* reading order (shuffle)"]},{"cell_type":"code","metadata":{"id":"b4dGZE1adAS7"},"source":["# Use DataLoader to generate minibatches\n","BATCH_SIZE = 256\n","train_dataloader = torch.utils.data.DataLoader(\n","    train_ds,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True)\n","val_dataloader = torch.utils.data.DataLoader(\n","    val_ds,\n","    batch_size=BATCH_SIZE)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Check shape of data\n","\n","N: number of samples\n","\n","C: channels\n","\n","H: Height\n","\n","W: Width\n","\n","**PyTorch use channel first !**"],"metadata":{"id":"wYt-k517xcUA"}},{"cell_type":"code","metadata":{"id":"W8M240hdc-_d"},"source":["for x, y in train_dataloader:\n","    print(\"type \", type(x), type(y))\n","    print(\"Shape of x [N, C, H, W]: \", x.shape, x.dtype)\n","    print(\"Shape of y [N]: \", y.shape, y.dtype)\n","    break"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# permute: [C, H, W] -> [H, W, C]\n","plt.imshow(x[0].permute(1, 2, 0)), y[0]"],"metadata":{"id":"LkRyhzfDgYhc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8STKvep1eC4v"},"source":["#### Build Model"]},{"cell_type":"code","metadata":{"id":"avl7U7gSe64u"},"source":["# Get cpu or gpu device for training.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using device: {device}\")\n","\n","IMG_SIZE = 32"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["nn.Sequential"],"metadata":{"id":"gV6Hf0chFDYR"}},{"cell_type":"code","source":["model = nn.Sequential(\n","    nn.Flatten(), # (C, H, W) -> (C*H*W)\n","    nn.Linear(in_features=IMG_SIZE*IMG_SIZE*3, out_features=64), # (C*H*W) -> (64)\n","    nn.ReLU(), # activation\n","    nn.Linear(64, 128), # (64) -> (128)\n","    nn.ReLU(),\n","    nn.Linear(128, 128),\n","    nn.ReLU(),\n","    nn.Linear(128, NUM_CLASS), # (128) -> NUM_CLASS\n",")"],"metadata":{"id":"utPUwXW1WKiM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["nn.Module Subclass"],"metadata":{"id":"sdI4--uRFF2w"}},{"cell_type":"code","metadata":{"id":"J9fUwxRZfJL3"},"source":["# Define model\n","class NeuralNet(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.flatten = nn.Flatten() # (C, H, W) -> (C*H*W)\n","        self.base_model = nn.Sequential(\n","            nn.Linear(in_features=IMG_SIZE*IMG_SIZE*3, out_features=64), # (C*H*W) -> (64)\n","            nn.ReLU(),\n","            nn.Linear(64, 128), # (64) -> (128)\n","            nn.ReLU(),\n","            nn.Linear(128, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, NUM_CLASS), # (128) -> NUM_CLASS\n","        )\n","    def forward(self, x):\n","        x = self.flatten(x)\n","        logits = self.base_model(x)\n","        return logits"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PVImZHyCgeDy"},"source":["# init model and move to GPU device\n","model = NeuralNet().to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wivbMuaEwMpp"},"source":["# Print basic model architecture\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yv0xgdSKgxXt"},"source":["# Use torchsummary to print advanced info\n","import torchsummary\n","\n","torchsummary.summary(model, input_size=(3, 32, 32))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use torchinfo to print advanced info\n","!pip install torchinfo\n","\n","import torchinfo\n","torchinfo.summary(model, input_size=(BATCH_SIZE, 3, 32, 32))"],"metadata":{"id":"5Wnn17WKurLj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vtOqbCgkd9PZ"},"source":["#### Training: Optimizing the Model Parameters"]},{"cell_type":"code","metadata":{"id":"uNNVOuzhhTOj"},"source":["loss_fn = nn.CrossEntropyLoss() # Softmax + negative log likelihood loss (nn.NLLLoss)\n","optimizer = torch.optim.SGD(\n","    params=model.parameters(), # parameters to optimize\n","    lr=1e-2, # learning rate: 1e-4, 1e-2...\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"r6foJpLOjmYN"},"source":["def train(dataloader, model, loss_fn, optimizer):\n","    size = len(dataloader.dataset) # number of samples\n","    num_batches = len(dataloader) # batches per epoch\n","\n","    model.train() # to training mode.\n","    epoch_loss, epoch_correct = 0, 0\n","    for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n","        x, y = x.to(device), y.to(device) # move data to device\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # Compute prediction loss\n","        pred = model(x)\n","        loss = loss_fn(pred, y)\n","\n","        # Optimization by gradients\n","        loss.backward() # backpropagation to compute gradients\n","        optimizer.step() # update model params\n","\n","        # write to logs\n","        epoch_loss += loss.item() # tensor -> python value\n","        # (N, Class)\n","        epoch_correct += (pred.argmax(dim=1) == y).sum().item()\n","\n","    # return avg loss of epoch, acc of epoch\n","    return epoch_loss/num_batches, epoch_correct/size\n","\n","\n","def test(dataloader, model, loss_fn):\n","    size = len(dataloader.dataset) # number of samples\n","    num_batches = len(dataloader) # batches per epoch\n","\n","    model.eval() # model to test mode.\n","    epoch_loss, epoch_correct = 0, 0\n","\n","    # No gradient for test data\n","    with torch.no_grad():\n","        for batch_i, (x, y) in enumerate(tqdm(dataloader, leave=False)):\n","            x, y = x.to(device), y.to(device)\n","\n","            # Compute prediction loss\n","            pred = model(x)\n","            loss = loss_fn(pred, y)\n","\n","            # write to logs\n","            epoch_loss += loss.item()\n","            epoch_correct += (pred.argmax(1) == y).sum().item()\n","\n","    return epoch_loss/num_batches, epoch_correct/size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IpXLEk2HiLPi"},"source":["EPOCHS = 10\n","logs = {\n","    'train_loss': [], 'train_acc': [],\n","    'val_loss': [], 'val_acc': []\n","}\n","for epoch in tqdm(range(EPOCHS)):\n","    train_loss, train_acc = train(train_dataloader, model, loss_fn, optimizer)\n","    val_loss, val_acc = test(val_dataloader, model, loss_fn)\n","\n","    print(f'EPOCH: {epoch} \\\n","    train_loss: {train_loss:.4f}, train_acc: {train_acc:.3f} \\\n","    val_loss: {val_loss:.4f}, val_acc: {val_acc:.3f} ')\n","\n","    logs['train_loss'].append(train_loss)\n","    logs['train_acc'].append(train_acc)\n","    logs['val_loss'].append(val_loss)\n","    logs['val_acc'].append(val_acc)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rvInhyibpdiY"},"source":["#### Logs"]},{"cell_type":"code","metadata":{"id":"guBMgShGz7jq"},"source":["# Plot loss curve\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.title('Loss')\n","plt.plot(logs['train_loss'])\n","plt.plot(logs['val_loss'])\n","plt.legend(['train_loss', 'val_loss'])\n","# plot acc\n","plt.subplot(1, 2, 2)\n","plt.title('Accuracy')\n","plt.plot(logs['train_acc'])\n","plt.plot(logs['val_acc'])\n","plt.legend(['train_acc', 'val_acc'])\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kIvqVEbiuAqz"},"source":["#### Save Model"]},{"cell_type":"markdown","source":["Saving & Loading Model (weights only)\n","\n","**Recommended**"],"metadata":{"id":"aN0b_DPT1CsC"}},{"cell_type":"code","source":["# model parameters\n","model.state_dict()"],"metadata":{"id":"Z9y9wlXgDXsf"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OAWJyTLWt-nE"},"source":["PATH = './model_weights.pth'\n","# save weights\n","torch.save(model.state_dict(), PATH)\n","\n","# load weights\n","model.load_state_dict(torch.load(PATH))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Saving & Loading Model (entire model)"],"metadata":{"id":"YM2J5jT11J78"}},{"cell_type":"code","source":["MODEL_PATH = './model.pth'\n","# save model\n","torch.save(model, MODEL_PATH)\n","# load model\n","model = torch.load(MODEL_PATH)"],"metadata":{"id":"RS9F6zW51OZ8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h_wOV5WuCnb"},"source":["#### Evaluation"]},{"cell_type":"code","metadata":{"id":"9MT2u1TGuMoF"},"source":["# load model\n","model = NeuralNet()\n","\n","model.load_state_dict(torch.load(PATH))\n","model.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# take first 2 images\n","n = 2\n","for (images, labels) in val_dataloader:\n","    images, labels = images[:n], labels[:n]\n","    images_grid = torchvision.utils.make_grid(images[:n])\n","    images_grid = images_grid.permute(1, 2, 0) # (C, H, W) -> (H, W, C)\n","    plt.imshow(images_grid.numpy())\n","    break"],"metadata":{"id":"9PMbgz8g-Vz8"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"X9iXXH_pt0nl"},"source":["# take first 2 images\n","n = 2\n","for (images, labels) in val_dataloader:\n","    images, labels = images[:n], labels[:n]\n","    break\n","\n","# Predict by model\n","with torch.no_grad():\n","    pred = model(images) # predict logits\n","print('raw_prediction logtis', pred, pred.shape, sep=\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_softmax = nn.Softmax(dim=1)(pred) # probabilities\n","print('prediction after softmax', pred_softmax, pred_softmax.shape, sep=\"\\n\")"],"metadata":{"id":"W_-AAW6w_c--"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NenCAHfduumi"},"source":["# max_prob: max probability of each samples\n","# predicted_cls: the index of max prob\n","max_prob, predicted_cls = torch.max(pred_softmax, dim=1)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_cls = pred_softmax.argmax(dim=1)"],"metadata":{"id":"ygulA8Hd_j7W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["predicted_cls"],"metadata":{"id":"SAjL_q7K_p4p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pred_softmax.argmax(dim=1)"],"metadata":{"id":"itABaVZEE-dn"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FpISPISQvrtd"},"source":["print('GroundTruth: ', ' '.join(class_names[labels[j]] for j in range(n)))\n","print('Prediction: ', ' '.join(class_names[predicted_cls[j]] for j in range(n)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"miysWGOOlaoU"},"execution_count":null,"outputs":[]}]}