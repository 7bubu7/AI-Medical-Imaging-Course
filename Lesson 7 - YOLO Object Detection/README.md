ğŸ“¦ Lesson 07 â€“ YOLO for Object Detection (BCCD Dataset)

This lesson introduces the fundamentals of object detection and the YOLO (You Only Look Once) algorithm series. Through hands-on implementation with the BCCD blood cell dataset, I explored how to train and evaluate YOLOv7 and YOLOv8 models using annotated medical images.

---

 ğŸ§  What I Learned

- Basics of object detection: bounding boxes, IoU, NMS
- Evolution from YOLOv1 to YOLOv8: architecture and improvements
- Anchor boxes and grid systems in detection models
- Understanding YOLO prediction outputs
- YOLO loss functions and training structure
- How to annotate datasets in PASCAL VOC format
- Practical use of YOLOv7 and YOLOv8 for medical image detection


---

 ğŸ““ Notebooks

- `YOLOv7-BCCD.ipynb`: Object detection using YOLOv7 with custom training on blood cell images  
- `YOLOv8-BCCD.ipynb`: Object detection using Ultralyticsâ€™ YOLOv8 high-level API

---

 ğŸ› ï¸ Tools Used

- Google Colab  
- PyTorch / Ultralytics  
- YOLOv7, YOLOv8  
- LabelImg (for annotation in PASCAL VOC format)  
- BCCD Dataset (Blood Cell Detection)  

---

 ğŸ”— References

- [YOLOv7 GitHub](https://github.com/WongKinYiu/yolov7)  
- [YOLOv8 GitHub](https://github.com/ultralytics/ultralytics)  
- [LabelImg annotation tool](https://github.com/heartexlabs/labelImg)  
- [BCCD dataset on Roboflow](https://public.roboflow.com/object-detection/bccd)  

---

> ğŸ’¡ For running the notebooks, make sure to install required packages (e.g., `ultralytics`) and use a GPU runtime in Colab.
